{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-CNN_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "0omBbUDV5mOd"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0Sf2jP3Q5Xg4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural network on the full stuff"
      ]
    },
    {
      "metadata": {
        "id": "k3rA4R1k5sEx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparation"
      ]
    },
    {
      "metadata": {
        "id": "0omBbUDV5mOd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Package installation"
      ]
    },
    {
      "metadata": {
        "id": "UT06o8Kx5WAM",
        "colab_type": "code",
        "outputId": "16a9ec13-420d-4292-84f3-623908b77c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install psutil\n",
        "!pip3 install librosa\n",
        "!pip3 install -U -q PyDrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Collecting librosa\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/b4/5b411f19de48f8fc1a0ff615555aa9124952e4156e94d4803377e50cfa4c/librosa-0.6.2.tar.gz (1.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.6MB 5.2MB/s \n",
            "\u001b[?25hCollecting audioread>=2.0.0 (from librosa)\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/41/8cd160c6b2046b997d571a744a7f398f39e954a62dd747b2aae1ad7f07d4/audioread-2.1.6.tar.gz\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.19.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.13.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.3.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
            "Collecting resampy>=0.2.0 (from librosa)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/b6/66a06d85474190b50aee1a6c09cdc95bb405ac47338b27e9b21409da1760/resampy-0.2.1.tar.gz (322kB)\n",
            "\u001b[K    100% |████████████████████████████████| 327kB 25.7MB/s \n",
            "\u001b[?25hCollecting numba>=0.38.0 (from librosa)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/45/8d5fc45e5f760ac65906ba48dec98e99e7920c96783ac7248c5e31c9464e/numba-0.40.1-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.2MB 11.7MB/s \n",
            "\u001b[?25hCollecting llvmlite>=0.25.0dev0 (from numba>=0.38.0->librosa)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/fb/f9c2e9e0ef2b54c52f0b727cf6af75b68c3d7ddb6d88c8d557b1b16bc1ab/llvmlite-0.25.0-cp36-cp36m-manylinux1_x86_64.whl (16.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 16.1MB 2.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: librosa, audioread, resampy\n",
            "  Running setup.py bdist_wheel for librosa ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/18/b8/10/f0f8f6ac60668a5cd75596cf14c25bb6b3ea1ecd815f058b7e\n",
            "  Running setup.py bdist_wheel for audioread ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/53/02/90/7b5c4081b7470c550ab605f600bad237dde12a6b8999b11f50\n",
            "  Running setup.py bdist_wheel for resampy ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ff/4f/ed/2e6c676c23efe5394bb40ade50662e90eb46e29b48324c5f9b\n",
            "Successfully built librosa audioread resampy\n",
            "Installing collected packages: audioread, llvmlite, numba, resampy, librosa\n",
            "Successfully installed audioread-2.1.6 librosa-0.6.2 llvmlite-0.25.0 numba-0.40.1 resampy-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v5zdVrAw5drt",
        "colab_type": "code",
        "outputId": "b874ba2a-6ca1-44cc-f259-46f69228b3be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# to install pytorch on colab\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5794e000 @  0x7ff9103f52a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LQUbK8tA5frC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "\n",
        "import psutil\n",
        "import pickle\n",
        "\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YJRQ5-CB5hWW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "obVIrwzR9ZiY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data download"
      ]
    },
    {
      "metadata": {
        "id": "8W0jlKMS9a4V",
        "colab_type": "code",
        "outputId": "48e4e532-b06e-45b1-ea44-d7a449f3525a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "print('Using gpu: %s ' % use_gpu)\n",
        "\n",
        "dtype = torch.FloatTensor\n",
        "if use_gpu:\n",
        "    dtype = torch.cuda.FloatTensor"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using gpu: True \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uwxyZuFJlPji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "google_drive_download = True\n",
        "google_drive_storage = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1vkLkU3lRh0",
        "colab_type": "code",
        "outputId": "b9c255a8-bfe9-4ddf-99b9-f49bcdef8093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "cell_type": "code",
      "source": [
        "# We can use Google Drive to both download our data and store the proper model.\n",
        "\n",
        "if google_drive_download:\n",
        "  \n",
        "  # Authenticate and create the PyDrive client.\n",
        "  # This only needs to be done once per notebook.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  gdrive = GoogleDrive(gauth)\n",
        "\n",
        "  test_id = \"1v76c_UdqCkF3do0DQjCKApwUrODBM9ay\"\n",
        "  downloaded = gdrive.CreateFile({'id': test_id})\n",
        "  downloaded.GetContentFile('test_dataset')\n",
        "\n",
        "  train_id_0 = \"1v-xA4pTanJHcH6eK1yecsGxDJRY6TS1D\"\n",
        "  downloaded = gdrive.CreateFile({'id': train_id_0})\n",
        "  downloaded.GetContentFile('train_dataset_0')\n",
        "\n",
        "  train_id_1 = \"1uxgvUUZmVRtlfDvfU9wvbZQvECd1PJ31\"\n",
        "  downloaded = gdrive.CreateFile({'id': train_id_1})\n",
        "  downloaded.GetContentFile('train_dataset_1')\n",
        "\n",
        "  validation_id = \"1uwrddUzD3HGb3ygVOiexpzJ7Y6wHZkk4\"\n",
        "  downloaded = gdrive.CreateFile({'id': validation_id})\n",
        "  downloaded.GetContentFile('validation_dataset')\n",
        "  \n",
        "  \n",
        "if google_drive_storage:\n",
        "  \n",
        "  drive.mount('/content/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "olgu2HYv5q3q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Unloading the .npz files"
      ]
    },
    {
      "metadata": {
        "id": "_7hWPMKB5vW1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filehandle = open('test_dataset', 'rb')\n",
        "test = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xiVl5dME8nHq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filehandle = open('validation_dataset', 'rb')\n",
        "validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cMc0IDXd45iN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filehandle = open('train_dataset_0', 'rb')\n",
        "train = pickle.load(filehandle)\n",
        "\n",
        "filehandle = open('train_dataset_1', 'rb')\n",
        "train = train + pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YIxRUTQh7-zF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN Classifier"
      ]
    },
    {
      "metadata": {
        "id": "w-9oaewc8BXl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data loader"
      ]
    },
    {
      "metadata": {
        "id": "nYSEnXoF8AR0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bs=100\n",
        "train_loader = torch.utils.data.DataLoader(train,\n",
        "    batch_size=bs, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation,\n",
        "    batch_size=bs, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test,\n",
        "    batch_size=bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mSHOKUGG8GXw",
        "colab_type": "code",
        "outputId": "ad4e91d5-e473-4c91-8edf-125d26ffe3b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(train[0][0].shape)\n",
        "print(train[0][1].shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 256])\n",
            "torch.Size([])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8gnTMvBO8LIi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define a convolutional neural network"
      ]
    },
    {
      "metadata": {
        "id": "Lwhxghw_8IZ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#we use 1-channel image \n",
        "\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        #64 3*3 filters with stride 1 \n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1)\n",
        "        #max pooling 2*4\n",
        "        self.pool = nn.MaxPool2d(2, 4)\n",
        "        #64 3*5 filters with stride 1\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding = 1)\n",
        "        self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3,5), stride = 1)\n",
        "        #max pooling 2*4\n",
        "        #dropout 0.2\n",
        "        self.dropout1 = nn.Dropout2d(p=0.2, inplace=False)\n",
        "        #fully connected layer 32 nerous to pervious ones \n",
        "        self.fc1 = nn.Linear(64 * 3 * 1, 32)\n",
        "        #dropout 0.2\n",
        "        self.dropout2 = nn.Dropout(p=0.2, inplace = False)\n",
        "        #output layers 8 nerous fully connected \n",
        "        self.fc2 = nn.Linear(32, 8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        \n",
        "        x = self.dropout1(x)\n",
        "        #print(x.shape)\n",
        "        x = x.view(-1, 64 * 3 * 1)\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        #print(x.shape)\n",
        "        x = F.softmax(self.fc2(x), 1)\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZIothGKQ8QcX",
        "colab_type": "code",
        "outputId": "ea5bf110-32eb-4ffe-d5cd-07adfa458e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "net = Net()\n",
        "\n",
        "\n",
        "model_filename = 'gdrive/My Drive/Colab Notebooks/data/NEW_MODEL_0'\n",
        "\n",
        "try:\n",
        "  train_info_file = open(model_filename, 'rb')\n",
        "  train_info = pickle.load(train_info_file)\n",
        "  net.load_state_dict(train_info['parameters'])\n",
        "  \n",
        "  #net.load_state_dict(torch.load(model_filename))\n",
        "  print(\"Parameters loaded from %s\" % model_filename)\n",
        "  \n",
        "except:\n",
        "  print(\"Pre-trained parameters not found\")\n",
        "\n",
        " "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters loaded from gdrive/My Drive/Colab Notebooks/data/NEW_MODEL_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8nblx6Aw8Vpn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training function"
      ]
    },
    {
      "metadata": {
        "id": "0_XzCuXg8UHJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss criterion: cross entropy\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YymWmY_-8a0h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(net = net, epochs = 2, train_info = None, bs = bs,\n",
        "                validation = True, lr = 0.01, model_save = None):\n",
        "  \n",
        "  net.train()\n",
        "  optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
        "  start_time = time.time()\n",
        "  \n",
        "  if train_info == None:\n",
        "    train_info = {'epochs': 0,\n",
        "                  'lr': [],\n",
        "                 'loss_train': [],\n",
        "                 'acc_train': [],\n",
        "                 'loss_val': [],\n",
        "                 'acc_val': [],\n",
        "                 'parameters': []}\n",
        "\n",
        "  loss_train = []\n",
        "  acc_train = []\n",
        "  \n",
        "  loss_val = []\n",
        "  acc_val = []\n",
        "  \n",
        "  for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    print('Epoch %s – Time lapsed: %s' % (str(epoch), str(time.time() - start_time)))    \n",
        "    \n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "    size = 0\n",
        "    \n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "      # get the inputs\n",
        "      inputs, labels = data\n",
        "        \n",
        "      if use_gpu:\n",
        "        inputs.cuda()\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward + backward + optimize\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "        \n",
        "      pred = outputs.max(1, keepdim=True)[1]\n",
        "        \n",
        "      size += bs\n",
        "      running_loss += loss.item()\n",
        "      running_corrects += pred.eq(labels.view_as(pred)).sum()\n",
        "      \n",
        "        \n",
        "    epoch_loss = running_loss / size\n",
        "    epoch_acc = running_corrects.item() / size\n",
        "    loss_train += [epoch_loss]\n",
        "    acc_train += [epoch_acc]\n",
        "    \n",
        "    if validation == True:\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      net.eval()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for val_i, val_data in enumerate(validation_loader):\n",
        "          val_images, val_labels = val_data\n",
        "          val_outputs = net(val_images)\n",
        "          _, predicted = torch.max(val_outputs.data, 1)\n",
        "          total += val_labels.size(0)\n",
        "          correct += (predicted == val_labels).sum().item()\n",
        "\n",
        "      print('Accuracy of the network on the validation tracks: %f' % (\n",
        "          correct / total))\n",
        "      \n",
        "      train_info['epochs'] += 1\n",
        "      train_info['lr'] += [lr]\n",
        "      train_info['loss_train'] += [epoch_loss]\n",
        "      train_info['acc_train'] += [epoch_acc]\n",
        "      train_info['acc_val'] += [correct / total]\n",
        "      \n",
        "      if max(train_info['acc_val']) == correct / total:\n",
        "        train_info['parameters'] = net.state_dict()\n",
        "        \n",
        "      if model_save is not None:\n",
        "        filehandle = open(str(model_save), 'wb')\n",
        "        pickle.dump(train_info, filehandle)\n",
        "        filehandle.close()\n",
        "      \n",
        "      net.train()\n",
        "    \n",
        "    print('Train - Loss: {:.4f} Acc: {:.4f}\\n'.format(epoch_loss, epoch_acc))\n",
        "\n",
        "  print('Finished Training')\n",
        "  \n",
        "  return train_info"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t0W89qCP8fso",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ]
    },
    {
      "metadata": {
        "id": "ReAg2weL8gmI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainer(learning = [(10, 0.01)], net = net, train_info = None, model_save = None):\n",
        "  \n",
        "  \"\"\"\n",
        "  `learning_rates` should be a list where each element is a tuple of size two.\n",
        "    - The first element should be the learning rate,\n",
        "    - The second element should be the number of epochs the user wants for this\n",
        "      particular learning rate.\n",
        "  \"\"\"\n",
        "  \n",
        "  loss_train, acc_train, loss_val, acc_val = [], [], [], []\n",
        "  \n",
        "  for learning_tuple in learning:\n",
        "    \n",
        "    train_info = train_model(net,\n",
        "                             learning_tuple[0],\n",
        "                             train_info,\n",
        "                             validation = True,\n",
        "                             lr = learning_tuple[1],\n",
        "                             model_save = model_save)\n",
        "    \n",
        "    #loss_train += list(new_loss_train)\n",
        "    #acc_train += list(new_acc_train)\n",
        "    #loss_val += list(new_loss_val)\n",
        "    #acc_val += list(new_acc_val)\n",
        "    \n",
        "\n",
        "  if model_save is not None:\n",
        "    filehandler = open(str(model_save), 'wb')\n",
        "    pickle.dump(train_info, filehandler)\n",
        "    #torch.save(net.state_dict(), str(model_save) + '.pt')\n",
        "  \n",
        "  return train_info\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7KcvN1am8cj5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train_info = trainer([(10, 0.1)], model_save = 'gdrive/My Drive/Colab Notebooks/data/NEW_MODEL_0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fPlYe1wmcFEv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train_info = trainer([(15, 0.05)], train_info, model_save = 'gdrive/My Drive/Colab Notebooks/data/NEW_MODEL_0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_xc9qRebJFWR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train_info = trainer([(29, 0.01)], train_info, model_save = 'gdrive/My Drive/Colab Notebooks/data/NEW_MODEL_0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yvUxuWoWcQw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1802
        },
        "outputId": "1d186000-803e-4a90-99ac-ac4c15f97930"
      },
      "cell_type": "code",
      "source": [
        "train_info = trainer([(26, 0.001)], train_info, model_save = 'gdrive/My Drive/Colab Notebooks/data/NEW_MODEL_0')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 – Time lapsed: 5.0067901611328125e-06\n",
            "Accuracy of the network on the validation tracks: 0.418375\n",
            "Train - Loss: 0.0187 Acc: 0.4045\n",
            "\n",
            "Epoch 1 – Time lapsed: 1383.235746383667\n",
            "Accuracy of the network on the validation tracks: 0.419750\n",
            "Train - Loss: 0.0187 Acc: 0.4047\n",
            "\n",
            "Epoch 2 – Time lapsed: 2713.98912024498\n",
            "Accuracy of the network on the validation tracks: 0.418500\n",
            "Train - Loss: 0.0187 Acc: 0.4040\n",
            "\n",
            "Epoch 3 – Time lapsed: 4036.203604698181\n",
            "Accuracy of the network on the validation tracks: 0.419750\n",
            "Train - Loss: 0.0186 Acc: 0.4048\n",
            "\n",
            "Epoch 4 – Time lapsed: 5337.857761621475\n",
            "Accuracy of the network on the validation tracks: 0.418500\n",
            "Train - Loss: 0.0186 Acc: 0.4041\n",
            "\n",
            "Epoch 5 – Time lapsed: 6625.1471474170685\n",
            "Accuracy of the network on the validation tracks: 0.416750\n",
            "Train - Loss: 0.0187 Acc: 0.4044\n",
            "\n",
            "Epoch 6 – Time lapsed: 7936.3164830207825\n",
            "Accuracy of the network on the validation tracks: 0.420625\n",
            "Train - Loss: 0.0187 Acc: 0.4041\n",
            "\n",
            "Epoch 7 – Time lapsed: 9283.227795600891\n",
            "Accuracy of the network on the validation tracks: 0.418875\n",
            "Train - Loss: 0.0187 Acc: 0.4051\n",
            "\n",
            "Epoch 8 – Time lapsed: 10660.203362703323\n",
            "Accuracy of the network on the validation tracks: 0.417375\n",
            "Train - Loss: 0.0186 Acc: 0.4048\n",
            "\n",
            "Epoch 9 – Time lapsed: 12110.511098623276\n",
            "Accuracy of the network on the validation tracks: 0.418375\n",
            "Train - Loss: 0.0186 Acc: 0.4056\n",
            "\n",
            "Epoch 10 – Time lapsed: 13560.621212244034\n",
            "Accuracy of the network on the validation tracks: 0.417625\n",
            "Train - Loss: 0.0186 Acc: 0.4052\n",
            "\n",
            "Epoch 11 – Time lapsed: 14985.271846294403\n",
            "Accuracy of the network on the validation tracks: 0.418125\n",
            "Train - Loss: 0.0186 Acc: 0.4068\n",
            "\n",
            "Epoch 12 – Time lapsed: 16344.156316518784\n",
            "Accuracy of the network on the validation tracks: 0.419250\n",
            "Train - Loss: 0.0186 Acc: 0.4060\n",
            "\n",
            "Epoch 13 – Time lapsed: 17728.846930503845\n",
            "Accuracy of the network on the validation tracks: 0.419250\n",
            "Train - Loss: 0.0186 Acc: 0.4054\n",
            "\n",
            "Epoch 14 – Time lapsed: 19112.976324796677\n",
            "Accuracy of the network on the validation tracks: 0.419250\n",
            "Train - Loss: 0.0186 Acc: 0.4064\n",
            "\n",
            "Epoch 15 – Time lapsed: 20498.146087884903\n",
            "Accuracy of the network on the validation tracks: 0.421375\n",
            "Train - Loss: 0.0186 Acc: 0.4064\n",
            "\n",
            "Epoch 16 – Time lapsed: 21897.922188282013\n",
            "Accuracy of the network on the validation tracks: 0.421375\n",
            "Train - Loss: 0.0186 Acc: 0.4083\n",
            "\n",
            "Epoch 17 – Time lapsed: 23316.07898926735\n",
            "Accuracy of the network on the validation tracks: 0.421875\n",
            "Train - Loss: 0.0186 Acc: 0.4071\n",
            "\n",
            "Epoch 18 – Time lapsed: 24733.519824028015\n",
            "Accuracy of the network on the validation tracks: 0.423125\n",
            "Train - Loss: 0.0186 Acc: 0.4066\n",
            "\n",
            "Epoch 19 – Time lapsed: 26150.068434238434\n",
            "Accuracy of the network on the validation tracks: 0.421250\n",
            "Train - Loss: 0.0186 Acc: 0.4080\n",
            "\n",
            "Epoch 20 – Time lapsed: 27547.66256928444\n",
            "Accuracy of the network on the validation tracks: 0.420375\n",
            "Train - Loss: 0.0186 Acc: 0.4070\n",
            "\n",
            "Epoch 21 – Time lapsed: 28952.378895998\n",
            "Accuracy of the network on the validation tracks: 0.422250\n",
            "Train - Loss: 0.0186 Acc: 0.4082\n",
            "\n",
            "Epoch 22 – Time lapsed: 30362.607802391052\n",
            "Accuracy of the network on the validation tracks: 0.423125\n",
            "Train - Loss: 0.0186 Acc: 0.4085\n",
            "\n",
            "Epoch 23 – Time lapsed: 31748.704526424408\n",
            "Accuracy of the network on the validation tracks: 0.422625\n",
            "Train - Loss: 0.0186 Acc: 0.4091\n",
            "\n",
            "Epoch 24 – Time lapsed: 33130.836159706116\n",
            "Accuracy of the network on the validation tracks: 0.419375\n",
            "Train - Loss: 0.0186 Acc: 0.4092\n",
            "\n",
            "Epoch 25 – Time lapsed: 34510.78813076019\n",
            "Accuracy of the network on the validation tracks: 0.419500\n",
            "Train - Loss: 0.0186 Acc: 0.4091\n",
            "\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ddaN1fdn_49z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "28be5f4b-6407-4e23-8d9d-63248043804e"
      },
      "cell_type": "code",
      "source": [
        "train_info = trainer([(10, 0.1)], train_info, model_save = None)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 – Time lapsed: 3.337860107421875e-06\n",
            "Accuracy of the network on the validation tracks: 0.131250\n",
            "Train - Loss: 0.0202 Acc: 0.2517\n",
            "\n",
            "Epoch 1 – Time lapsed: 1346.694977760315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-26a3bcd5018c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-f69da42cc120>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(learning, train_info, model_save)\u001b[0m\n\u001b[1;32m     17\u001b[0m                              \u001b[0mvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                              \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                              model_save = model_save)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#loss_train += list(new_loss_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-04d23312970f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, epochs, train_info, bs, validation, lr, model_save)\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "81d_yHmrTRTj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Testing the model"
      ]
    },
    {
      "metadata": {
        "id": "POtBc5BjTSTy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_model(data_loader = test_loader, net = net):\n",
        "  \"\"\"\n",
        "  Runs the model on the test dataset (individual tracks)\n",
        "  \"\"\"\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  predictions = []\n",
        "\n",
        "  net.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(data_loader):\n",
        "      images, labels = data\n",
        "      outputs = net(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      predictions += [predicted]\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  \n",
        "  score = 100 * (correct / total)\n",
        "  print('Accuracy of the network on the test tracks (3 second windows): %f %%' % score)\n",
        "  return correct / total\n",
        "\n",
        "\n",
        "def test_model_full(data_loader = test_loader, net = net):\n",
        "  \n",
        "  \"\"\"\n",
        "  Runs the model on the test dataset, where the songs are recombined into their\n",
        "  original length (30 second).\n",
        "  \n",
        "  For each track, the final prediction is the genre that is predicted the most\n",
        "  often for our 3-second windows: for example, if among our 10 samples, we have\n",
        "  5 predictions for Rock, 3 for Instrumental and 2 for Pop, then the final\n",
        "  prediction will be \"Rock\". In case of a tie, this algorithm will return the\n",
        "  genre whose code is the lowest: for instance, Pop is represented by the label\n",
        "  '6' and Rock by the label '7', so if there is a tie between those two, the\n",
        "  function will return the prediction 'Pop'.\n",
        "  \"\"\"\n",
        "  \n",
        "  correct = 0\n",
        "  total = 0\n",
        "  \n",
        "  net.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for i, data in enumerate(data_loader):\n",
        "      \n",
        "      images, labels = data\n",
        "      outputs = net(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      \n",
        "      full_song_labels = [label for song_index, label in enumerate(labels)\n",
        "                          if song_index % 10 == 0]\n",
        "      \n",
        "      total += len(full_song_labels)\n",
        "      prediction = []\n",
        "      \n",
        "      for window in range(0,100,10):\n",
        "        \n",
        "        distribution = torch.bincount(predicted[window:(window+10)])\n",
        "\n",
        "        # Note: when two or more genres have the same number of votes,\n",
        "        # it automatically picks the first in the list\n",
        "        song_voted = torch.argmax(distribution)\n",
        "        prediction += [song_voted]\n",
        "      \n",
        "      correct += len([label for label, pred in zip(full_song_labels,prediction) if label == pred])\n",
        "    \n",
        "    score = 100 * (correct / total)\n",
        "    print('Accuracy of the network on the test tracks (full tracks): %f %%' % score)\n",
        "    return correct / total\n",
        "      \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2trUow_b30Eo",
        "colab_type": "code",
        "outputId": "55399e8c-4c19-4d71-fc44-7b76f69743e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "single_window_accuracy = test_model(test_loader, net)\n",
        "track_accuracy = test_model_full()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test tracks (3 second windows): 43.725000 %\n",
            "Accuracy of the network on the test tracks (full tracks): 49.750000 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "swW81BXaZeCY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}